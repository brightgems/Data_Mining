{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries different models on the preprocessed airbnb dataset using Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Preprocessed data with 'data_first_booking' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "data = pd.read_csv('preprocessed_airbnb_train.csv')\n",
    "labels = data.loc[:,'country_destination']\n",
    "data = data.drop(['country_destination'], axis=1)\n",
    "\n",
    "def folds_to_split(data,targets,train,test):\n",
    "    data_tr = pd.DataFrame(data).iloc[train]\n",
    "    data_te = pd.DataFrame(data).iloc[test]\n",
    "    labels_tr = pd.DataFrame(targets).iloc[train]\n",
    "    labels_te = pd.DataFrame(targets).iloc[test]\n",
    "    return [data_tr, data_te, labels_tr, labels_te]\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "def ndcg_score(te_labels, predict, k):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(len(predict) + 1))\n",
    "    T = lb.transform(te_labels)\n",
    "    scores = []\n",
    "\n",
    "    for y_true, y_score in zip(T, predict):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)  \n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the max-depth of the Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1, Max-depth : 1, Score : 0.914630585321\n",
      "Fold : 1, Max-depth : 2, Score : 0.914630585321\n",
      "Fold : 1, Max-depth : 3, Score : 0.920932777486\n",
      "Fold : 1, Max-depth : 4, Score : 0.922777094909\n",
      "Fold : 2, Max-depth : 1, Score : 0.916515064953\n",
      "Fold : 2, Max-depth : 2, Score : 0.916515064953\n",
      "Fold : 2, Max-depth : 3, Score : 0.922745835777\n",
      "Fold : 2, Max-depth : 4, Score : 0.924148418009\n",
      "Fold : 3, Max-depth : 1, Score : 0.915203504403\n",
      "Fold : 3, Max-depth : 2, Score : 0.915203504403\n",
      "Fold : 3, Max-depth : 3, Score : 0.921028620066\n",
      "Fold : 3, Max-depth : 4, Score : 0.922495212253\n",
      "Fold : 4, Max-depth : 1, Score : 0.914359339211\n",
      "Fold : 4, Max-depth : 2, Score : 0.914359339211\n",
      "Fold : 4, Max-depth : 3, Score : 0.920640176937\n",
      "Fold : 4, Max-depth : 4, Score : 0.923650754396\n",
      "Fold : 5, Max-depth : 1, Score : 0.914549312078\n",
      "Fold : 5, Max-depth : 2, Score : 0.914549312078\n",
      "Fold : 5, Max-depth : 3, Score : 0.921183034291\n",
      "Fold : 5, Max-depth : 4, Score : 0.922889579245\n",
      "Fold : 6, Max-depth : 1, Score : 0.914557524571\n",
      "Fold : 6, Max-depth : 2, Score : 0.914557524571\n",
      "Fold : 6, Max-depth : 3, Score : 0.921263432845\n",
      "Fold : 6, Max-depth : 4, Score : 0.923768950666\n",
      "Fold : 7, Max-depth : 1, Score : 0.913833562359\n",
      "Fold : 7, Max-depth : 2, Score : 0.913833562359\n",
      "Fold : 7, Max-depth : 3, Score : 0.919814190597\n",
      "Fold : 7, Max-depth : 4, Score : 0.921623118394\n",
      "Fold : 8, Max-depth : 1, Score : 0.914933141972\n",
      "Fold : 8, Max-depth : 2, Score : 0.914933141972\n",
      "Fold : 8, Max-depth : 3, Score : 0.92098846257\n",
      "Fold : 8, Max-depth : 4, Score : 0.923398410823\n",
      "Fold : 9, Max-depth : 1, Score : 0.913814934206\n",
      "Fold : 9, Max-depth : 2, Score : 0.913814934206\n",
      "Fold : 9, Max-depth : 3, Score : 0.920039481504\n",
      "Fold : 9, Max-depth : 4, Score : 0.922284121972\n",
      "Fold : 10, Max-depth : 1, Score : 0.913777846064\n",
      "Fold : 10, Max-depth : 2, Score : 0.913777846064\n",
      "Fold : 10, Max-depth : 3, Score : 0.919801773688\n",
      "Fold : 10, Max-depth : 4, Score : 0.921530344607\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "foldnum=0\n",
    "\n",
    "for train, test in cross_validation.KFold(len(data), shuffle=True, n_folds=10,\n",
    "                                           random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(data, labels, train, test)\n",
    "\n",
    "    for max_depth in range(1, 5):\n",
    "        rf = RandomForestClassifier(n_estimators=600,criterion='gini', max_depth=max_depth)\n",
    "        rf = rf.fit(tr_data, tr_labels.values.ravel())\n",
    "        rf_predict = rf.predict_proba(te_data) \n",
    "        score = ndcg_score(te_labels.as_matrix(), rf_predict, k=5)\n",
    "        print 'Fold : {}, Max-depth : {}, Score : {}'.format( foldnum, max_depth, score )\n",
    "        results.loc[foldnum, 'max_depth=%d'%max_depth ] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_depth=1    0.914617\n",
       "max_depth=2    0.914617\n",
       "max_depth=3    0.920844\n",
       "max_depth=4    0.922857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the nDCG score increases with the max-depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without setting the max-depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foldnum=0\n",
    "results = pd.DataFrame()\n",
    "for train, test in cross_validation.KFold(len(data), shuffle=True, n_folds=10,\n",
    "                                           random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(data, labels, train, test)\n",
    "    rf = RandomForestClassifier(n_estimators=600,criterion='gini')\n",
    "    rf = rf.fit(tr_data, tr_labels.values.ravel())\n",
    "    rf_predict = rf.predict_proba(te_data) \n",
    "    score = ndcg_score(te_labels.as_matrix(), rf_predict, k=5)\n",
    "    results.loc[foldnum, 'no max-depth' ] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no max-depth    0.922605\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nDCG score of this model is comparable to max-depth = 4. This great score is attributed to the bias by the 'date_first_booking' which will be NULL for all the new users whose prediction need to be made. A good model will be the one without the 'date_first_booking' attribute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Preprocessed data without 'date_first_booking'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen during the exploratory analysis, 58% of the data has the country destination as 'NDF' (No Destination Found). Also, it was found that there is a 1-to-1 correlation betweeen NaN 'date_first_booking' and 'NDF'. That is, the date_first_booking is NaN for all the instances whose country destination is 'NDF'. The high score seen in the above section can be attributed to this factor. So, inorder to get a more realistic model, in this section I will try to build models on the preprocessed data without the date_first_booking information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without setting the max-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_nodfb = data.drop(['dfb_year', 'dfb_month', 'dfb_day'], axis=1)\n",
    "data_nodfb = pd.DataFrame(preprocessing.StandardScaler().fit_transform(data_nodfb))\n",
    "foldnum=0\n",
    "results = pd.DataFrame()\n",
    "for train, test in cross_validation.KFold(len(data_nodfb), shuffle=True, n_folds=10,\n",
    "                                           random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(data_nodfb, labels, train, test)\n",
    "    rf = RandomForestClassifier(n_estimators=600,criterion='gini')\n",
    "    rf = rf.fit(tr_data, tr_labels.values.ravel())\n",
    "    rf_predict = rf.predict_proba(te_data) \n",
    "    score = ndcg_score(te_labels.as_matrix(), rf_predict, k=5)\n",
    "    results.loc[foldnum, 'no max-depth + dfb' ] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no max-depth + dfb    0.798816\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the max-depth of the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1, Max-depth : 3, Score : 0.806603278112\n",
      "Fold : 1, Max-depth : 4, Score : 0.807644004479\n",
      "Fold : 1, Max-depth : 5, Score : 0.813657558096\n",
      "Fold : 1, Max-depth : 6, Score : 0.815575904147\n",
      "Fold : 1, Max-depth : 7, Score : 0.817798973216\n",
      "Fold : 2, Max-depth : 3, Score : 0.809882411297\n",
      "Fold : 2, Max-depth : 4, Score : 0.810416757163\n",
      "Fold : 2, Max-depth : 5, Score : 0.815790087715\n",
      "Fold : 2, Max-depth : 6, Score : 0.818261826421\n",
      "Fold : 2, Max-depth : 7, Score : 0.819612470421\n",
      "Fold : 3, Max-depth : 3, Score : 0.80805296249\n",
      "Fold : 3, Max-depth : 4, Score : 0.809195815682\n",
      "Fold : 3, Max-depth : 5, Score : 0.815075575493\n",
      "Fold : 3, Max-depth : 6, Score : 0.81708537894\n",
      "Fold : 3, Max-depth : 7, Score : 0.818048298655\n",
      "Fold : 4, Max-depth : 3, Score : 0.807295250859\n",
      "Fold : 4, Max-depth : 4, Score : 0.808037918371\n",
      "Fold : 4, Max-depth : 5, Score : 0.814331568223\n",
      "Fold : 4, Max-depth : 6, Score : 0.815774110584\n",
      "Fold : 4, Max-depth : 7, Score : 0.817337687929\n",
      "Fold : 5, Max-depth : 3, Score : 0.807901033914\n",
      "Fold : 5, Max-depth : 4, Score : 0.808835565461\n",
      "Fold : 5, Max-depth : 5, Score : 0.815044597252\n",
      "Fold : 5, Max-depth : 6, Score : 0.817252979064\n",
      "Fold : 5, Max-depth : 7, Score : 0.819410127179\n",
      "Fold : 6, Max-depth : 3, Score : 0.807320529099\n",
      "Fold : 6, Max-depth : 4, Score : 0.808236936832\n",
      "Fold : 6, Max-depth : 5, Score : 0.814119859755\n",
      "Fold : 6, Max-depth : 6, Score : 0.815713853014\n",
      "Fold : 6, Max-depth : 7, Score : 0.817652078956\n",
      "Fold : 7, Max-depth : 3, Score : 0.805541833459\n",
      "Fold : 7, Max-depth : 4, Score : 0.806545527854\n",
      "Fold : 7, Max-depth : 5, Score : 0.814067736003\n",
      "Fold : 7, Max-depth : 6, Score : 0.816940578139\n",
      "Fold : 7, Max-depth : 7, Score : 0.818326998207\n",
      "Fold : 8, Max-depth : 3, Score : 0.806658703784\n",
      "Fold : 8, Max-depth : 4, Score : 0.807836971502\n",
      "Fold : 8, Max-depth : 5, Score : 0.813643402954\n",
      "Fold : 8, Max-depth : 6, Score : 0.816758978864\n",
      "Fold : 8, Max-depth : 7, Score : 0.818093913708\n",
      "Fold : 9, Max-depth : 3, Score : 0.805868186442\n",
      "Fold : 9, Max-depth : 4, Score : 0.807060412464\n",
      "Fold : 9, Max-depth : 5, Score : 0.813172195504\n",
      "Fold : 9, Max-depth : 6, Score : 0.814718482137\n",
      "Fold : 9, Max-depth : 7, Score : 0.816552794512\n",
      "Fold : 10, Max-depth : 3, Score : 0.806938536967\n",
      "Fold : 10, Max-depth : 4, Score : 0.808097847769\n",
      "Fold : 10, Max-depth : 5, Score : 0.814125676555\n",
      "Fold : 10, Max-depth : 6, Score : 0.816352012886\n",
      "Fold : 10, Max-depth : 7, Score : 0.8178377941\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "foldnum=0\n",
    "for train, test in cross_validation.KFold(len(data_nodfb), shuffle=True, n_folds=10,\n",
    "                                           random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(data_nodfb, labels, train, test)\n",
    "\n",
    "    for max_depth in range(3, 8):\n",
    "        rf = RandomForestClassifier(n_estimators=600,criterion='gini', max_depth=max_depth)\n",
    "        rf = rf.fit(tr_data, tr_labels.values.ravel())\n",
    "        rf_predict = rf.predict_proba(te_data) \n",
    "        score = ndcg_score(te_labels.as_matrix(), rf_predict, k=5)\n",
    "        print 'Fold : {}, Max-depth : {}, Score : {}'.format( foldnum, max_depth, score )\n",
    "        results.loc[foldnum, 'max_depth=%d'%max_depth ] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_depth=3    0.807206\n",
       "max_depth=4    0.808191\n",
       "max_depth=5    0.814303\n",
       "max_depth=6    0.816443\n",
       "max_depth=7    0.818067\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the nDCG score increases with the max-depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1, Min_S_Leafs : 5, Score : 0.820407923331\n",
      "Fold : 1, Min_S_Leafs : 20, Score : 0.82328392834\n",
      "Fold : 1, Min_S_Leafs : 50, Score : 0.823381799044\n",
      "Fold : 2, Min_S_Leafs : 5, Score : 0.820952535189\n",
      "Fold : 2, Min_S_Leafs : 20, Score : 0.82424557707\n",
      "Fold : 2, Min_S_Leafs : 50, Score : 0.824723487734\n",
      "Fold : 3, Min_S_Leafs : 5, Score : 0.820148906935\n",
      "Fold : 3, Min_S_Leafs : 20, Score : 0.82330198963\n",
      "Fold : 3, Min_S_Leafs : 50, Score : 0.823316477575\n",
      "Fold : 4, Min_S_Leafs : 5, Score : 0.820739348248\n",
      "Fold : 4, Min_S_Leafs : 20, Score : 0.823767843772\n",
      "Fold : 4, Min_S_Leafs : 50, Score : 0.823351386668\n",
      "Fold : 5, Min_S_Leafs : 5, Score : 0.821490008094\n",
      "Fold : 5, Min_S_Leafs : 20, Score : 0.82444853059\n",
      "Fold : 5, Min_S_Leafs : 50, Score : 0.824486743072\n",
      "Fold : 6, Min_S_Leafs : 5, Score : 0.819904565882\n",
      "Fold : 6, Min_S_Leafs : 20, Score : 0.821756134553\n",
      "Fold : 6, Min_S_Leafs : 50, Score : 0.82249002024\n",
      "Fold : 7, Min_S_Leafs : 5, Score : 0.821301910698\n",
      "Fold : 7, Min_S_Leafs : 20, Score : 0.824648070352\n",
      "Fold : 7, Min_S_Leafs : 50, Score : 0.824781304274\n",
      "Fold : 8, Min_S_Leafs : 5, Score : 0.821409298304\n",
      "Fold : 8, Min_S_Leafs : 20, Score : 0.823619007097\n",
      "Fold : 8, Min_S_Leafs : 50, Score : 0.82363861689\n",
      "Fold : 9, Min_S_Leafs : 5, Score : 0.817516775284\n",
      "Fold : 9, Min_S_Leafs : 20, Score : 0.820618122742\n",
      "Fold : 9, Min_S_Leafs : 50, Score : 0.820702014073\n",
      "Fold : 10, Min_S_Leafs : 5, Score : 0.819895514046\n",
      "Fold : 10, Min_S_Leafs : 20, Score : 0.822283843115\n",
      "Fold : 10, Min_S_Leafs : 50, Score : 0.822434685902\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "foldnum=0\n",
    "for train, test in cross_validation.KFold(len(data_nodfb), shuffle=True, n_folds=10,\n",
    "                                           random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(data_nodfb, labels, train, test)\n",
    "\n",
    "    for min_sample_leafs in [5, 20, 50]:\n",
    "        rf = RandomForestClassifier(n_estimators=600,criterion='gini', min_samples_leaf=min_sample_leafs)\n",
    "        rf = rf.fit(tr_data, tr_labels.values.ravel())\n",
    "        rf_predict = rf.predict_proba(te_data) \n",
    "        score = ndcg_score(te_labels.as_matrix(), rf_predict, k=5)\n",
    "        print 'Fold : {}, Min_S_Leafs : {}, Score : {}'.format( foldnum, min_sample_leafs, score )\n",
    "        results.loc[foldnum, 'min_s_leafs=%d'%min_sample_leafs ] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min_s_leafs=5     0.820377\n",
       "min_s_leafs=20    0.823197\n",
       "min_s_leafs=50    0.823331\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The min_sample_leafs 20 and 50 gives almost the same nDCG score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying max_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1, max_leaf_nodes : 5, Score : 0.806015421447\n",
      "Fold : 1, max_leaf_nodes : 6, Score : 0.806015421447\n",
      "Fold : 1, max_leaf_nodes : 7, Score : 0.806015421447\n",
      "Fold : 1, max_leaf_nodes : 8, Score : 0.806568698308\n",
      "Fold : 1, max_leaf_nodes : 9, Score : 0.806707017524\n",
      "Fold : 1, max_leaf_nodes : 10, Score : 0.80712197517\n",
      "Fold : 1, max_leaf_nodes : 11, Score : 0.807191134777\n",
      "Fold : 2, max_leaf_nodes : 5, Score : 0.809520139448\n",
      "Fold : 2, max_leaf_nodes : 6, Score : 0.809520139448\n",
      "Fold : 2, max_leaf_nodes : 7, Score : 0.809726794889\n",
      "Fold : 2, max_leaf_nodes : 8, Score : 0.809916992721\n",
      "Fold : 2, max_leaf_nodes : 9, Score : 0.810194477214\n",
      "Fold : 2, max_leaf_nodes : 10, Score : 0.810418423367\n",
      "Fold : 2, max_leaf_nodes : 11, Score : 0.810971726149\n",
      "Fold : 3, max_leaf_nodes : 5, Score : 0.807707148251\n",
      "Fold : 3, max_leaf_nodes : 6, Score : 0.807707148251\n",
      "Fold : 3, max_leaf_nodes : 7, Score : 0.807707148251\n",
      "Fold : 3, max_leaf_nodes : 8, Score : 0.808070253202\n",
      "Fold : 3, max_leaf_nodes : 9, Score : 0.808208578898\n",
      "Fold : 3, max_leaf_nodes : 10, Score : 0.80858897456\n",
      "Fold : 3, max_leaf_nodes : 11, Score : 0.808796463104\n",
      "Fold : 4, max_leaf_nodes : 5, Score : 0.80694943662\n",
      "Fold : 4, max_leaf_nodes : 6, Score : 0.80694943662\n",
      "Fold : 4, max_leaf_nodes : 7, Score : 0.807156925163\n",
      "Fold : 4, max_leaf_nodes : 8, Score : 0.807329832283\n",
      "Fold : 4, max_leaf_nodes : 9, Score : 0.80757190225\n",
      "Fold : 4, max_leaf_nodes : 10, Score : 0.807796681505\n",
      "Fold : 4, max_leaf_nodes : 11, Score : 0.807900425777\n",
      "Fold : 5, max_leaf_nodes : 5, Score : 0.807381479453\n",
      "Fold : 5, max_leaf_nodes : 6, Score : 0.807381479453\n",
      "Fold : 5, max_leaf_nodes : 7, Score : 0.807381479453\n",
      "Fold : 5, max_leaf_nodes : 8, Score : 0.80779645654\n",
      "Fold : 5, max_leaf_nodes : 9, Score : 0.807813747252\n",
      "Fold : 5, max_leaf_nodes : 10, Score : 0.808228724339\n",
      "Fold : 5, max_leaf_nodes : 11, Score : 0.808644534527\n",
      "Fold : 6, max_leaf_nodes : 5, Score : 0.806853679877\n",
      "Fold : 6, max_leaf_nodes : 6, Score : 0.806853679877\n",
      "Fold : 6, max_leaf_nodes : 7, Score : 0.807043877708\n",
      "Fold : 6, max_leaf_nodes : 8, Score : 0.807285947676\n",
      "Fold : 6, max_leaf_nodes : 9, Score : 0.807752796898\n",
      "Fold : 6, max_leaf_nodes : 10, Score : 0.807873831882\n",
      "Fold : 6, max_leaf_nodes : 11, Score : 0.807994866865\n",
      "Fold : 7, max_leaf_nodes : 5, Score : 0.805005821389\n",
      "Fold : 7, max_leaf_nodes : 6, Score : 0.805005821389\n",
      "Fold : 7, max_leaf_nodes : 7, Score : 0.805074984236\n",
      "Fold : 7, max_leaf_nodes : 8, Score : 0.805541833459\n",
      "Fold : 7, max_leaf_nodes : 9, Score : 0.805541833459\n",
      "Fold : 7, max_leaf_nodes : 10, Score : 0.806129717665\n",
      "Fold : 7, max_leaf_nodes : 11, Score : 0.80626804336\n",
      "Fold : 8, max_leaf_nodes : 5, Score : 0.806330180257\n",
      "Fold : 8, max_leaf_nodes : 6, Score : 0.806330180257\n",
      "Fold : 8, max_leaf_nodes : 7, Score : 0.806503087376\n",
      "Fold : 8, max_leaf_nodes : 8, Score : 0.806589540936\n",
      "Fold : 8, max_leaf_nodes : 9, Score : 0.807090971582\n",
      "Fold : 8, max_leaf_nodes : 10, Score : 0.807350332261\n",
      "Fold : 8, max_leaf_nodes : 11, Score : 0.807454076533\n",
      "Fold : 9, max_leaf_nodes : 5, Score : 0.805523205305\n",
      "Fold : 9, max_leaf_nodes : 6, Score : 0.805523205305\n",
      "Fold : 9, max_leaf_nodes : 7, Score : 0.80574798456\n",
      "Fold : 9, max_leaf_nodes : 8, Score : 0.805955473104\n",
      "Fold : 9, max_leaf_nodes : 9, Score : 0.806387740902\n",
      "Fold : 9, max_leaf_nodes : 10, Score : 0.806507109682\n",
      "Fold : 9, max_leaf_nodes : 11, Score : 0.806628977768\n",
      "Fold : 10, max_leaf_nodes : 5, Score : 0.806367943473\n",
      "Fold : 10, max_leaf_nodes : 6, Score : 0.806367943473\n",
      "Fold : 10, max_leaf_nodes : 7, Score : 0.806506269168\n",
      "Fold : 10, max_leaf_nodes : 8, Score : 0.806938536967\n",
      "Fold : 10, max_leaf_nodes : 9, Score : 0.807301641918\n",
      "Fold : 10, max_leaf_nodes : 10, Score : 0.807423510003\n",
      "Fold : 10, max_leaf_nodes : 11, Score : 0.807595584021\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "foldnum=0\n",
    "for train, test in cross_validation.KFold(len(data_nodfb), shuffle=True, n_folds=10,\n",
    "                                           random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(data_nodfb, labels, train, test)\n",
    "\n",
    "    for max_leaf_nodes in range(5, 12):\n",
    "        rf = RandomForestClassifier(n_estimators=600, criterion='gini', max_depth=7, \n",
    "                                    max_leaf_nodes=max_leaf_nodes )\n",
    "        rf = rf.fit(tr_data, tr_labels.values.ravel())\n",
    "        rf_predict = rf.predict_proba(te_data) \n",
    "        score = ndcg_score(te_labels.as_matrix(), rf_predict, k=5)\n",
    "        print 'Fold : {}, max_leaf_nodes : {}, Score : {}'.format( foldnum, max_leaf_nodes, score )\n",
    "        results.loc[foldnum, 'max_leaf_nodes=%d'%max_leaf_nodes ] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_leaf_nodes=5     0.806765\n",
       "max_leaf_nodes=6     0.806765\n",
       "max_leaf_nodes=7     0.806886\n",
       "max_leaf_nodes=8     0.807199\n",
       "max_leaf_nodes=9     0.807457\n",
       "max_leaf_nodes=10    0.807744\n",
       "max_leaf_nodes=11    0.807945\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying the max_leaf_nodes made the nDCG score worse compared to min_sample_leafs and max_depth values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810542490776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "[tr_data, te_data, \n",
    " tr_labels, te_labels] = cross_validation.train_test_split(data_nodfb, labels, random_state=20160202, test_size=0.33)\n",
    "\n",
    "rf =  AdaBoostClassifier(RandomForestClassifier(n_estimators=600, criterion='gini', min_samples_leaf=50), \n",
    "                             random_state=20160202)\n",
    "rf = rf.fit(tr_data, tr_labels.values.ravel())\n",
    "rf_predict = rf.predict_proba(te_data) \n",
    "score = ndcg_score(te_labels.as_matrix(), rf_predict, k=5)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I was hoping that applying AdaBoost on top of the best Random forest would improve the nDCG score. But as can be seen above, the nDCG score decreased.\n",
    "\n",
    "The best nDCG score among all thest models is 0.823337, which was obtained with min_samples_leaf = 50  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
